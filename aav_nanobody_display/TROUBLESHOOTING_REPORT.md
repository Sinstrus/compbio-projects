# VHH Structure Prediction - Troubleshooting Report
**Date:** 2025-12-13
**Goal:** Local GPU-based protein structure prediction on RTX 3070 Ti
**Status:** IN PROGRESS - Multiple approaches failed, needs continuation

---

## System Specifications

```
Hardware:
- GPU: NVIDIA GeForce RTX 3070 Ti Laptop GPU
- VRAM: 8192 MiB (8.6 GB)
- System RAM: 16 GB (13 GB available)
- CPU: x86_64 Linux

Software:
- OS: Linux (WSL2)
- CUDA: 13.0
- Driver: 581.80 (nvidia-smi: 580.105.07)
- Python: 3.11.14 (conda)
- PyTorch: 2.6.0+cu124 ‚úì CUDA WORKING
- Conda environment: aav_nanobody

Working Directory: /home/cnguy/projects/aav_nanobody_display
```

## GPU Verification - WORKING ‚úì

The GPU is **fully functional** and accessible:

```bash
# Test performed:
python -c "import torch; x = torch.randn(1000, 1000).cuda(); print(f'GPU: {x.device}')"
# Result: GPU tensor created successfully on cuda:0

# Small protein model test:
# ESM-2 (8M params) loaded and ran inference successfully
# GPU Memory: 0.04 GB during inference
```

**Key Finding:** GPU works perfectly. Issue is with **large model loading into system RAM**, not GPU.

---

## Target Sequence

```
VHH Nanobody (119 amino acids):
EVQLVESGGGLVQPGGSLRLSCAASGFTFSTADMGWFRQAPGKGRELVAAVSGSGFSTYSDSVEGRFTISRDNAKRMVYLQMNSLRAEDTAVYYCAKATISLYYAMDVWGQGTTVTVSS
```

---

## Attempted Approaches

### 1. HuggingFace ESMFold ‚ùå

**Attempt:**
```bash
pip install transformers accelerate
# Used: facebook/esmfold_v1 model
```

**Result:** FAILED - Exit code 137 (OOM killed)

**Details:**
- Model size: ~15 GB when fully loaded into RAM
- Download: ~3 GB
- Issue: Process killed during model loading phase (system RAM exhaustion, NOT GPU)
- GPU never engaged (no nvidia-smi activity)
- Downloaded to: `~/.cache/huggingface/`

**Files Created:**
- `/home/cnguy/projects/aav_nanobody_display/test_prediction_hf.py`
- `/home/cnguy/projects/aav_nanobody_display/test_prediction_optimized.py`

**Why it failed:** HuggingFace ESMFold loads entire model into system RAM before transferring to GPU. 16GB system RAM insufficient.

---

### 2. Fair-ESM with OpenFold Dependencies ‚ùå

**Attempt:**
```bash
pip install fair-esm
pip install "fair-esm[esmfold]"  # Installs extra dependencies
```

**Result:** FAILED - Missing `openfold` package

**Openfold Installation Attempts:**

#### 2a. PyPI Installation
```bash
pip install openfold
```
Result: Package not found (not on PyPI)

#### 2b. Conda Installation
```bash
mamba install -c conda-forge -c bioconda openfold
```
Result: Package doesn't exist in conda channels

#### 2c. GitHub Installation
```bash
pip install "git+https://github.com/aqlaboratory/openfold.git@4b41059694619831a7db195b7e0988fc4ff3a307"
```
Result: FAILED - Multiple issues:
1. `ModuleNotFoundError: No module named 'torch'` during build (despite torch being installed)
2. With `--no-build-isolation`: CUDA version detection error
   ```
   TypeError: unsupported operand type(s) for +: 'NoneType' and 'str'
   File "<string>", line 40, in get_cuda_bare_metal_version
   ```

**Dependencies Installed:**
- omegaconf ‚úì
- hydra-core ‚úì
- biotite ‚úì
- deepspeed ‚úì
- pytorch-lightning ‚úì
- dm-tree ‚úì
- einops ‚úì

**Why it failed:** OpenFold has complex build dependencies and CUDA version detection issues. Setup.py incompatible with current environment.

---

### 3. OmegaFold ‚ùå

**Attempt:**
```bash
pip install "git+https://github.com/HeliXonProtein/OmegaFold.git"
```

**Result:** FAILED - Python version incompatibility

**Error:**
```
Exception: Python 3.11.14 | packaged by conda-forge | (main, Oct 22 2025, 22:46:25) [GCC 14.3.0] is not supported.
```

**Why it failed:** OmegaFold doesn't support Python 3.11. Would require creating new environment with Python 3.9 or 3.10.

---

### 4. ESM-1b Contact Prediction ‚ùå

**Approach:** Use smaller ESM-1b model (650MB) for contact prediction, then build structure with distance geometry.

**Attempt:**
```bash
python predict_structure_local.py
```

**Result:** FAILED - Process hung during model download

**Details:**
- Model: `esm1b_t33_650M_UR50S` (1.5 GB)
- Download location: `~/.cache/torch/hub/checkpoints/`
- Download started: 17:00
- Process killed: 17:14 (after 14+ minutes)
- File at kill time: `esm1b_t33_650M_UR50S.pt.22b8885aead840e8b93e20c8fc5c6a9e.partial` (1.5 GB)
- Download appeared complete but model never loaded to GPU
- Process (PID 31468) remained in 'Sl' state (sleeping, interruptible)
- No GPU activity ever observed in nvidia-smi

**Why it failed:** Unknown. Possibly:
1. Network issue during download
2. Model loading stalled
3. Silent error in ESM library

**File Created:**
- `/home/cnguy/projects/aav_nanobody_display/predict_structure_local.py`

---

### 5. LocalColabFold ‚ùå

**Attempt:**
```bash
wget https://raw.githubusercontent.com/YoshitakaMo/localcolabfold/main/install_colabfold_linux.sh
bash install_colabfold_linux.sh
```

**Result:** FAILED - Exit code 8

**Details:**
- Installation script executed
- No detailed error output captured
- Background process terminated with exit code 8

**Why it failed:** Unknown. Installation script issue.

---

## What DOES Work

1. **PyTorch + CUDA:** ‚úì Verified working
2. **Small ESM-2 models:** ‚úì (8M-650M parameter models load and run)
3. **GPU tensor operations:** ‚úì Confirmed GPU utilization
4. **ESM embeddings:** ‚úì Can generate protein embeddings
5. **Dependencies:** All standard packages (numpy, biopython, py3dmol) installed

**Test file that works:**
```bash
source ~/miniforge3/bin/activate aav_nanobody
python test_gpu_simple.py  # SUCCESS - Uses ESM-2 8M model
```

---

## Key Insights

### Memory Bottleneck
- **System RAM (not GPU VRAM) is the bottleneck**
- Large models load into CPU RAM first, then transfer to GPU
- 16 GB system RAM insufficient for models that expand to >10 GB during loading
- GPU has plenty of VRAM (8 GB) but never gets engaged

### Model Size Comparison
| Model | Download Size | RAM Usage | VRAM Usage | Status |
|-------|--------------|-----------|------------|---------|
| ESM-2 (8M) | 35 MB | ~100 MB | ~40 MB | ‚úì Works |
| ESM-2 (650M) | ~650 MB | ~2 GB | ~500 MB | ‚úì Should work |
| ESM-1b (contact) | 1.5 GB | ~3 GB | ~1 GB | ? Untested |
| ESMFold (HF) | ~3 GB | ~15 GB | ~6 GB | ‚úó OOM |
| OmegaFold | Unknown | Unknown | Unknown | ‚úó Python 3.11 |

---

## Recommended Next Steps for Claude Opus

### Option 1: Fix ESM-1b Download/Loading Issue (RECOMMENDED)

The ESM-1b approach is promising but stalled. Debug why:

1. **Clear cache and retry:**
   ```bash
   rm -rf ~/.cache/torch/hub/checkpoints/esm1b*
   python predict_structure_local.py
   ```

2. **Monitor in real-time:**
   ```bash
   watch -n 1 'ls -lh ~/.cache/torch/hub/checkpoints/ && nvidia-smi | grep python'
   ```

3. **Add verbose logging to script:**
   - Add print statements after model download
   - Check if model.to('cuda') is actually called
   - Verify model loads before GPU transfer

### Option 2: Use Smaller Python Environment

Create Python 3.9 environment for OmegaFold:

```bash
mamba create -n omegafold python=3.9 -y
mamba activate omegafold
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
pip install "git+https://github.com/HeliXonProtein/OmegaFold.git"
```

OmegaFold is specifically designed to be more memory-efficient than ESMFold.

### Option 3: Try RGN2 (Smaller Model)

RGN2 is an older but much smaller protein folding model:

```bash
pip install tensorflow  # RGN2 uses TensorFlow
# Clone and run RGN2
```

### Option 4: Use ESM-2 + Rosetta/PyRosetta

Two-stage approach:
1. Use ESM-2 (works!) to predict contacts/distances
2. Use Rosetta (classical) to build structure from constraints

```bash
# ESM-2 for contacts (works already)
# Then install PyRosetta or use Rosetta web service
```

### Option 5: Docker-based ESMFold

Use pre-built Docker container:

```bash
docker pull ghcr.io/sokrypton/esmfold:latest
# Run with GPU passthrough
nvidia-docker run --gpus all -v $(pwd):/data esmfold ...
```

Containerized environment may handle dependencies better.

---

## File Locations

### Created Scripts
```
/home/cnguy/projects/aav_nanobody_display/
‚îú‚îÄ‚îÄ test_vhh.fasta                          # Input sequence
‚îú‚îÄ‚îÄ test_prediction.py                      # Original fair-esm attempt
‚îú‚îÄ‚îÄ test_prediction_hf.py                   # HuggingFace ESMFold
‚îú‚îÄ‚îÄ test_prediction_optimized.py            # HF with FP16 optimization
‚îú‚îÄ‚îÄ test_gpu_simple.py                      # ‚úì WORKING - ESM-2 test
‚îú‚îÄ‚îÄ predict_structure_local.py              # ESM-1b contact prediction (hung)
‚îú‚îÄ‚îÄ predict_and_visualize.py                # API-based alternative
‚îú‚îÄ‚îÄ vhh_workflow.py                         # Workflow options script
‚îî‚îÄ‚îÄ TROUBLESHOOTING_REPORT.md              # This file
```

### Environment
```
Conda environment: aav_nanobody
Location: /home/cnguy/miniforge3/envs/aav_nanobody
Activation: source ~/miniforge3/bin/activate aav_nanobody
```

### Cache Directories
```
PyTorch models: ~/.cache/torch/hub/checkpoints/
HuggingFace models: ~/.cache/huggingface/
```

---

## Dependencies Installed

```
‚úì torch==2.6.0+cu124
‚úì torchvision==0.21.0+cu124
‚úì fair-esm==2.0.0
‚úì transformers==4.57.3
‚úì accelerate==1.12.0
‚úì biopython==1.86
‚úì pyyaml==6.0.3
‚úì py3dmol==2.5.3
‚úì omegaconf==2.3.0
‚úì biotite==1.5.0
‚úì deepspeed==0.5.9
‚úì pytorch-lightning==2.6.0
‚úì scipy==1.16.3
```

---

## Error Patterns to Watch For

1. **Exit code 137:** System OOM killer - reduce model size or batch size
2. **"No module named 'openfold'":** Fair-ESM esmfold requires manual openfold install
3. **CUDA version detection errors:** Setup.py issues with openfold
4. **Silent hangs:** Check if model is stuck in download or loading
5. **No GPU activity:** Model loading into CPU RAM, never transferring to GPU

---

## Questions for Debugging

1. Why did ESM-1b download complete but never load?
2. Can openfold be compiled with current CUDA setup?
3. Is there a working pre-built wheel for openfold?
4. Can we reduce ESMFold memory footprint with quantization?
5. Would Python 3.10 environment work better?

---

## Original Setup Guide Reference

The project included a setup guide that recommended:
- **ESMFold:** Fast (~30 sec) but requires setup
- **LocalColabFold:** Higher quality, more complex setup
- Optimized for RTX 3070 Ti with 8GB VRAM
- chunk_size=64 for memory optimization

File: `/home/cnguy/projects/aav_nanobody_display/SETUP_GUIDE_Structure_Prediction.md`

---

## Commands to Resume Debugging

```bash
# Activate environment
source ~/miniforge3/bin/activate aav_nanobody
cd /home/cnguy/projects/aav_nanobody_display

# Check GPU
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"

# Clear caches if needed
rm -rf ~/.cache/torch/hub/checkpoints/esm1b*
rm -rf ~/.cache/huggingface/hub/models--facebook--esmfold*

# Monitor resources
watch -n 1 'nvidia-smi; echo "---"; ps aux | grep python | grep -v grep'

# Test small model (verify GPU works)
python test_gpu_simple.py
```

---

## Success Criteria

A successful solution will:
1. ‚úì Run entirely on local GPU (RTX 3070 Ti)
2. ‚úì Predict structure for 119 AA VHH sequence
3. ‚úì Complete in <5 minutes
4. ‚úì Use <8 GB VRAM
5. ‚úì Use <13 GB system RAM
6. ‚úì Generate PDB file
7. ‚úì Create interactive 3D visualization (py3Dmol)

---

## Contact/Handoff

**For Claude Opus:**
- Read this file first: `/home/cnguy/projects/aav_nanobody_display/TROUBLESHOOTING_REPORT.md`
- Environment is ready: `source ~/miniforge3/bin/activate aav_nanobody`
- GPU is verified working
- Focus on **Option 1** (fix ESM-1b) or **Option 2** (OmegaFold with Python 3.9)

**User Requirements:**
- Must use local GPU (no online APIs)
- Must use small enough model to fit in memory
- Wants complete prediction + visualization workflow

Good luck! üöÄ
